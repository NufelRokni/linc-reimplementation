ipex flag is deprecated, will be removed in Accelerate v1.10. From 2.7.0, PyTorch has all needed optimizations for Intel CPU and XPU.
/opt/conda/envs/linc/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:492: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Selected Tasks: ['folio-baseline-8shot']
Loading the model and tokenizer from HF (in bf16)
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:03<00:20,  3.50s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:06<00:17,  3.40s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:10<00:13,  3.49s/it]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:14<00:10,  3.52s/it]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:17<00:06,  3.49s/it]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:28<00:06,  6.01s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:30<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████| 7/7 [00:30<00:00,  4.35s/it]
/opt/conda/envs/linc/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:999: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.
  warnings.warn(
Map:   0%|          | 0/204 [00:00<?, ? examples/s]Map:   4%|▍         | 8/204 [00:00<00:03, 65.03 examples/s]Map:  10%|█         | 21/204 [00:00<00:01, 92.54 examples/s]Map:  15%|█▌        | 31/204 [00:00<00:01, 88.13 examples/s]Map:  21%|██        | 42/204 [00:00<00:01, 90.45 examples/s]Map:  28%|██▊       | 57/204 [00:00<00:01, 90.56 examples/s]Map:  33%|███▎      | 67/204 [00:00<00:01, 88.59 examples/s]Map:  37%|███▋      | 76/204 [00:00<00:01, 85.97 examples/s]Map:  42%|████▏     | 85/204 [00:00<00:01, 85.17 examples/s]Map:  47%|████▋     | 96/204 [00:01<00:01, 89.85 examples/s]Map:  51%|█████▏    | 105/204 [00:01<00:01, 86.59 examples/s]Map:  57%|█████▋    | 116/204 [00:01<00:01, 66.65 examples/s]Map:  63%|██████▎   | 128/204 [00:02<00:02, 37.83 examples/s]Map:  68%|██████▊   | 138/204 [00:02<00:01, 45.48 examples/s]Map:  72%|███████▏  | 147/204 [00:02<00:01, 51.58 examples/s]Map:  77%|███████▋  | 158/204 [00:02<00:00, 59.47 examples/s]Map:  83%|████████▎ | 170/204 [00:02<00:00, 69.75 examples/s]Map:  90%|████████▉ | 183/204 [00:02<00:00, 81.68 examples/s]Map:  95%|█████████▍| 193/204 [00:02<00:00, 83.45 examples/s]Map: 100%|██████████| 204/204 [00:02<00:00, 76.37 examples/s]Map: 100%|██████████| 204/204 [00:02<00:00, 70.53 examples/s]
Filter:   0%|          | 0/204 [00:00<?, ? examples/s]Filter: 100%|██████████| 204/204 [00:00<00:00, 4429.78 examples/s]
number of problems for this task is 10
Using n_copies=1 (each task will be run 1 time(s) to generate up to 5 outputs, trimming to 5).
  0%|          | 0/10 [00:00<?, ?it/s] 10%|█         | 1/10 [01:38<14:44, 98.31s/it] 20%|██        | 2/10 [03:41<15:03, 112.88s/it] 30%|███       | 3/10 [08:19<21:59, 188.44s/it] 40%|████      | 4/10 [09:45<14:47, 148.00s/it] 50%|█████     | 5/10 [11:02<10:10, 122.18s/it] 60%|██████    | 6/10 [14:28<10:02, 150.71s/it] 70%|███████   | 7/10 [19:09<09:39, 193.25s/it] 80%|████████  | 8/10 [21:27<05:51, 175.82s/it] 90%|█████████ | 9/10 [21:54<02:09, 129.37s/it]100%|██████████| 10/10 [23:56<00:00, 127.11s/it]100%|██████████| 10/10 [23:56<00:00, 143.69s/it]
raw generations were saved
processed generations were saved
references were saved
{
  "config": {
    "model": "bigcode/starcoderplus"
  },
  "folio-baseline-8shot": {
    "accuracy (pass@1 majority)": 0.5
  }
}
